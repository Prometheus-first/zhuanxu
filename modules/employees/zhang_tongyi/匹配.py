import pandas as pd
import pymongo
from datetime import datetime
import os

def process_and_store_data(file_path):
    """
    æ•°æ®å¤„ç†é˜¶æ®µï¼šä»Excel/CSVè¯»å–æ•°æ®ï¼Œå¤„ç†åˆå¹¶åå­˜å…¥æ•°æ®åº“
    :param file_path: æ•°æ®æ–‡ä»¶è·¯å¾„
    """
    print("\n" + "="*60)
    print("ğŸ“Š æ•°æ®å¤„ç†ä¸å­˜å‚¨é˜¶æ®µ")
    print("="*60)

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(file_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return False

    # æ ¹æ®æ–‡ä»¶æ‰©å±•åé€‰æ‹©è¯»å–æ–¹å¼
    file_ext = os.path.splitext(file_path)[1].lower()
    try:
        if file_ext in ['.xlsx', '.xls']:
            print(f"ğŸ“– è¯»å–Excelæ–‡ä»¶: {file_path}")
            df1 = pd.read_excel(file_path)
        elif file_ext == '.csv':
            print(f"ğŸ“– è¯»å–CSVæ–‡ä»¶: {file_path}")
            df1 = pd.read_csv(file_path)
        else:
            print(f"âŒ ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_ext}")
            return False
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        return False

    print(f"âœ… æˆåŠŸè¯»å–æ•°æ®ï¼Œå…± {len(df1)} æ¡è®°å½•")

    # è¿æ¥MongoDB
    try:
        client = pymongo.MongoClient('mongodb://localhost:27017/')
        db = client['ç•™å­˜']  # æ•°æ®åº“åç§°
        collection = db['æ•°æ®']  # é›†åˆåç§°
        print("âœ… æˆåŠŸè¿æ¥MongoDBæ•°æ®åº“")
    except Exception as e:
        print(f"âŒ è¿æ¥æ•°æ®åº“å¤±è´¥: {e}")
        return False

    # å°†DataFrameè½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
    data_records = df1.to_dict('records')

    # å¤„ç†æ•°æ®æ ¼å¼å¹¶åˆå¹¶ç›¸åŒç”¨æˆ·çš„è®°å½•
    from collections import defaultdict

    print("ğŸ”„ å¼€å§‹æ•°æ®å¤„ç†...")

    # å…ˆå¤„ç†æ—¶é—´æ ¼å¼å’Œè®¿é—®æ—¶é•¿
    for record in data_records:
        # è½¬æ¢è®¿é—®æ—¶é—´
        if 'è®¿é—®æ—¶é—´' in record:
            try:
                record['è®¿é—®æ—¶é—´'] = datetime.strptime(record['è®¿é—®æ—¶é—´'], '%Y-%m-%d %H:%M:%S')
            except:
                pass

        # å¤„ç†è®¿é—®æ—¶é•¿ï¼šå°†"æœªçŸ¥"ã€ç©ºå€¼ã€Noneè½¬æ¢ä¸º0
        if 'è®¿é—®æ—¶é•¿' in record:
            duration = record['è®¿é—®æ—¶é•¿']
            if duration == 'æœªçŸ¥' or duration == '' or duration is None:
                record['è®¿é—®æ—¶é•¿'] = 0
            else:
                try:
                    record['è®¿é—®æ—¶é•¿'] = int(duration)
                except (ValueError, TypeError):
                    record['è®¿é—®æ—¶é•¿'] = 0

    # æŒ‰ IP + åœ°åŸŸ + æ—¥æœŸ åˆ†ç»„åˆå¹¶æ•°æ®
    merged_data = defaultdict(lambda: {
        'è®¿é—®æ¬¡æ•°': 0,
        'æ€»è®¿é—®æ—¶é•¿': 0,
        'æœ€æ—©è®¿é—®æ—¶é—´': None,
        'æœ€æ™šè®¿é—®æ—¶é—´': None,
        'å…¶ä»–ä¿¡æ¯': {}
    })

    for record in data_records:
        if record.get('è®¿é—®æ—¶é—´') and record.get('è®¿é—®ip') and record.get('åœ°åŸŸ'):
            # æå–æ—¥æœŸä½œä¸ºåˆ†ç»„é”®çš„ä¸€éƒ¨åˆ†
            visit_date = record['è®¿é—®æ—¶é—´'].date()
            group_key = (record['è®¿é—®ip'], record['åœ°åŸŸ'], visit_date)

            # ç´¯åŠ è®¿é—®æ¬¡æ•°å’Œæ—¶é•¿
            merged_data[group_key]['è®¿é—®æ¬¡æ•°'] += 1
            merged_data[group_key]['æ€»è®¿é—®æ—¶é•¿'] += record.get('è®¿é—®æ—¶é•¿', 0)

            # è®°å½•æœ€æ—©å’Œæœ€æ™šè®¿é—®æ—¶é—´
            current_time = record['è®¿é—®æ—¶é—´']
            if merged_data[group_key]['æœ€æ—©è®¿é—®æ—¶é—´'] is None or current_time < merged_data[group_key]['æœ€æ—©è®¿é—®æ—¶é—´']:
                merged_data[group_key]['æœ€æ—©è®¿é—®æ—¶é—´'] = current_time
            if merged_data[group_key]['æœ€æ™šè®¿é—®æ—¶é—´'] is None or current_time > merged_data[group_key]['æœ€æ™šè®¿é—®æ—¶é—´']:
                merged_data[group_key]['æœ€æ™šè®¿é—®æ—¶é—´'] = current_time

            # ä¿å­˜å…¶ä»–å­—æ®µä¿¡æ¯ï¼ˆä½¿ç”¨ç¬¬ä¸€æ¡è®°å½•çš„ä¿¡æ¯ï¼‰
            if not merged_data[group_key]['å…¶ä»–ä¿¡æ¯']:
                merged_data[group_key]['å…¶ä»–ä¿¡æ¯'] = {
                    'æ¥æº': record.get('æ¥æº', ''),
                    'å…³é”®è¯': record.get('å…³é”®è¯', ''),
                    'æœç´¢è¯': record.get('æœç´¢è¯', ''),
                    'å…¥å£ç•Œé¢': record.get('å…¥å£ç•Œé¢', ''),
                    'ç³»ç»Ÿ': record.get('ç³»ç»Ÿ', ''),
                    'æµè§ˆå™¨': record.get('æµè§ˆå™¨', ''),
                    'æ¥æºç±»å‹': record.get('æ¥æºç±»å‹', ''),
                    'ç½‘ç«™': record.get('ç½‘ç«™', ''),
                    'æµé‡ç±»å‹': record.get('æµé‡ç±»å‹', '')
                }

    # å°†åˆå¹¶åçš„æ•°æ®è½¬æ¢ä¸ºæœ€ç»ˆæ ¼å¼
    final_records = []
    for (ip, region, date), data in merged_data.items():
        final_record = {
            'è®¿é—®æ—¶é—´': data['æœ€æ—©è®¿é—®æ—¶é—´'],  # ä½¿ç”¨æœ€æ—©è®¿é—®æ—¶é—´
            'åœ°åŸŸ': region,
            'è®¿é—®ip': ip,
            'è®¿é—®æ—¥æœŸ': datetime.combine(date, datetime.min.time()),  # è½¬æ¢ä¸ºdatetimeå¯¹è±¡
            'è®¿é—®æ¬¡æ•°': data['è®¿é—®æ¬¡æ•°'],
            'è®¿é—®æ—¶é•¿': data['æ€»è®¿é—®æ—¶é•¿'],  # ä¿æŒåŸå­—æ®µåï¼Œä¾¿äºåç»­åˆ†æ
            'æ€»è®¿é—®æ—¶é•¿': data['æ€»è®¿é—®æ—¶é•¿'],  # åŒæ—¶ä¿ç•™æ–°å­—æ®µå
            'æœ€æ—©è®¿é—®æ—¶é—´': data['æœ€æ—©è®¿é—®æ—¶é—´'],
            'æœ€æ™šè®¿é—®æ—¶é—´': data['æœ€æ™šè®¿é—®æ—¶é—´'],
            **data['å…¶ä»–ä¿¡æ¯']  # å±•å¼€å…¶ä»–å­—æ®µ
        }
        final_records.append(final_record)

    print(f"åŸå§‹æ•°æ®: {len(data_records)} æ¡")
    print(f"åˆå¹¶åæ•°æ®: {len(final_records)} æ¡")
    print(f"åˆå¹¶äº† {len(data_records) - len(final_records)} æ¡é‡å¤è®°å½•")

    # æ˜¾ç¤ºåˆå¹¶ç¤ºä¾‹ï¼ˆå‰3ä¸ªæœ‰å¤šæ¬¡è®¿é—®çš„è®°å½•ï¼‰
    print("\nğŸ“Š åˆå¹¶ç¤ºä¾‹:")
    merge_examples = [(key, data) for key, data in merged_data.items() if data['è®¿é—®æ¬¡æ•°'] > 1]
    if merge_examples:
        for i, ((ip, region, date), data) in enumerate(merge_examples[:3]):
            print(f"\nç¤ºä¾‹ {i+1}:")
            print(f"  IP: {ip}, åœ°åŸŸ: {region}, æ—¥æœŸ: {date}")
            print(f"  è®¿é—®æ¬¡æ•°: {data['è®¿é—®æ¬¡æ•°']} æ¬¡")
            print(f"  æ€»è®¿é—®æ—¶é•¿: {data['æ€»è®¿é—®æ—¶é•¿']} ç§’")
            print(f"  è®¿é—®æ—¶é—´æ®µ: {data['æœ€æ—©è®¿é—®æ—¶é—´'].strftime('%H:%M:%S')} - {data['æœ€æ™šè®¿é—®æ—¶é—´'].strftime('%H:%M:%S')}")
    else:
        print("  æ²¡æœ‰å‘ç°éœ€è¦åˆå¹¶çš„é‡å¤è®°å½•")

    # æ˜¾ç¤ºè®¿é—®æ—¶é•¿å¤„ç†ç»Ÿè®¡
    print("\nğŸ“ˆ è®¿é—®æ—¶é•¿å¤„ç†ç»Ÿè®¡:")
    duration_stats = {'æœ‰æ•ˆæ—¶é•¿': 0, 'æœªçŸ¥è½¬æ¢': 0, 'ç©ºå€¼è½¬æ¢': 0, 'æ€»æ—¶é•¿': 0}
    for record in data_records:
        original_duration = record.get('è®¿é—®æ—¶é•¿')
        if original_duration == 0:
            if str(record.get('è®¿é—®æ—¶é•¿', '')).strip() in ['æœªçŸ¥', '']:
                duration_stats['æœªçŸ¥è½¬æ¢'] += 1
            else:
                duration_stats['ç©ºå€¼è½¬æ¢'] += 1
        else:
            duration_stats['æœ‰æ•ˆæ—¶é•¿'] += 1
        duration_stats['æ€»æ—¶é•¿'] += record.get('è®¿é—®æ—¶é•¿', 0)

    print(f"  æœ‰æ•ˆè®¿é—®æ—¶é•¿è®°å½•: {duration_stats['æœ‰æ•ˆæ—¶é•¿']} æ¡")
    print(f"  'æœªçŸ¥'è½¬æ¢ä¸º0: {duration_stats['æœªçŸ¥è½¬æ¢']} æ¡")
    print(f"  ç©ºå€¼è½¬æ¢ä¸º0: {duration_stats['ç©ºå€¼è½¬æ¢']} æ¡")
    print(f"  æ‰€æœ‰è®°å½•æ€»æ—¶é•¿: {duration_stats['æ€»æ—¶é•¿']} ç§’")

    # æ˜¾ç¤ºåˆå¹¶åæ•°æ®çš„å‰å‡ æ¡è®°å½•
    print("\nğŸ“‹ åˆå¹¶åæ•°æ®ç¤ºä¾‹:")
    for i, record in enumerate(final_records[:3]):
        print(f"\nè®°å½• {i+1}:")
        print(f"  è®¿é—®æ—¶é—´: {record['è®¿é—®æ—¶é—´']}")
        print(f"  IP: {record['è®¿é—®ip']}, åœ°åŸŸ: {record['åœ°åŸŸ']}")
        print(f"  è®¿é—®æ¬¡æ•°: {record['è®¿é—®æ¬¡æ•°']}")
        print(f"  è®¿é—®æ—¶é•¿: {record['è®¿é—®æ—¶é•¿']} ç§’")
        print(f"  æ¥æº: {record.get('æ¥æº', 'N/A')}")
        print(f"  æµè§ˆå™¨: {record.get('æµè§ˆå™¨', 'N/A')}")

    try:
        # æ‰¹é‡æ’å…¥åˆå¹¶åçš„æ•°æ®åˆ°MongoDB
        result = collection.insert_many(final_records)
        print(f"\nâœ… æ•°æ®æ’å…¥æˆåŠŸï¼")
        print(f"å…±æ’å…¥ {len(result.inserted_ids)} æ¡åˆå¹¶åçš„è®°å½•")
        print(f"æ’å…¥çš„æ–‡æ¡£IDç¤ºä¾‹: {result.inserted_ids[:3]}...")

    except Exception as e:
        print(f"âŒ æ’å…¥æ•°æ®æ—¶å‡ºé”™: {e}")
        return False

    finally:
        # å…³é—­è¿æ¥
        client.close()

    print("\nâœ… æ•°æ®å¤„ç†å®Œæˆï¼")
    return True

# ==================== ç•™å­˜åˆ†æåŠŸèƒ½ ====================

def analyze_retention(start_date=None, end_date=None):
    """
    åˆ†æç”¨æˆ·ç•™å­˜æƒ…å†µ
    :param start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ï¼š'2025-07-17' æˆ– datetimeå¯¹è±¡
    :param end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ï¼š'2025-07-27' æˆ– datetimeå¯¹è±¡
    :return: ç•™å­˜åˆ†æç»“æœ
    """
    try:
        # é‡æ–°è¿æ¥æ•°æ®åº“è¿›è¡ŒæŸ¥è¯¢
        client = pymongo.MongoClient('mongodb://localhost:27017/')
        db = client['ç•™å­˜']
        collection = db['æ•°æ®']

        # å¤„ç†æ—¥æœŸå‚æ•°
        query_filter = {}
        if start_date or end_date:
            time_filter = {}
            if start_date:
                if isinstance(start_date, str):
                    start_date = datetime.strptime(start_date, '%Y-%m-%d')
                time_filter["$gte"] = start_date
            if end_date:
                if isinstance(end_date, str):
                    end_date = datetime.strptime(end_date + ' 23:59:59', '%Y-%m-%d %H:%M:%S')
                time_filter["$lte"] = end_date
            query_filter["è®¿é—®æ—¶é—´"] = time_filter

        # è·å–æŒ‡å®šæ—¥æœŸèŒƒå›´å†…çš„æ•°æ®ï¼ŒæŒ‰æ—¶é—´æ’åº
        all_data = list(collection.find(query_filter).sort("è®¿é—®æ—¶é—´", 1))

        if not all_data:
            print("æŒ‡å®šæ—¥æœŸèŒƒå›´å†…æ²¡æœ‰æ•°æ®")
            return

        date_range_info = ""
        if start_date or end_date:
            start_str = start_date.strftime('%Y-%m-%d') if start_date else "å¼€å§‹"
            end_str = end_date.strftime('%Y-%m-%d') if end_date else "ç»“æŸ"
            date_range_info = f"ï¼ˆæ—¥æœŸèŒƒå›´: {start_str} åˆ° {end_str}ï¼‰"

        print(f"\nå¼€å§‹åˆ†æç•™å­˜æƒ…å†µ{date_range_info}...")
        print(f"åˆ†ææ•°æ®é‡: {len(all_data)} æ¡")

        # æŒ‰æ—¥æœŸåˆ†ç»„æ•°æ®
        from collections import defaultdict
        daily_users = defaultdict(set)  # {æ—¥æœŸ: {(ip, åœ°åŸŸ)}}

        for record in all_data:
            if record.get('è®¿é—®æ—¶é—´') and record.get('è®¿é—®ip') and record.get('åœ°åŸŸ'):
                # æå–æ—¥æœŸï¼ˆå»æ‰æ—¶åˆ†ç§’ï¼‰
                visit_date = record['è®¿é—®æ—¶é—´'].date()
                user_key = (record['è®¿é—®ip'], record['åœ°åŸŸ'])
                daily_users[visit_date].add(user_key)

        # åˆ†æç•™å­˜ - æ¯”è¾ƒæ¯ä¸€å¤©ä¸åç»­æ‰€æœ‰å¤©çš„ç•™å­˜æƒ…å†µ
        retention_results = []
        dates = sorted(daily_users.keys())

        for i, base_date in enumerate(dates):
            base_users = daily_users[base_date]

            # ä¸åç»­æ¯ä¸€å¤©è¿›è¡Œæ¯”è¾ƒ
            for j in range(i + 1, len(dates)):
                target_date = dates[j]
                target_users = daily_users[target_date]
                days_diff = (target_date - base_date).days

                # è®¡ç®—ç•™å­˜ç”¨æˆ·
                retained_users = base_users.intersection(target_users)
                retention_rate = len(retained_users) / len(base_users) if base_users else 0

                result = {
                    'åŸºå‡†æ—¥æœŸ': base_date,
                    'å¯¹æ¯”æ—¥æœŸ': target_date,
                    'é—´éš”å¤©æ•°': days_diff,
                    'åŸºå‡†æ—¥ç”¨æˆ·æ•°': len(base_users),
                    'å¯¹æ¯”æ—¥ç”¨æˆ·æ•°': len(target_users),
                    'ç•™å­˜ç”¨æˆ·æ•°': len(retained_users),
                    'ç•™å­˜ç‡': f"{retention_rate:.2%}",
                    'ç•™å­˜ç”¨æˆ·è¯¦æƒ…': list(retained_users)
                }
                retention_results.append(result)

        # è¾“å‡ºç»“æœ
        print(f"\n=== ç•™å­˜åˆ†æç»“æœ ===")
        for result in retention_results:
            print(f"\nåŸºå‡†æ—¥æœŸ: {result['åŸºå‡†æ—¥æœŸ']}")
            print(f"å¯¹æ¯”æ—¥æœŸ: {result['å¯¹æ¯”æ—¥æœŸ']} (é—´éš”{result['é—´éš”å¤©æ•°']}å¤©)")
            print(f"åŸºå‡†æ—¥ç”¨æˆ·æ•°: {result['åŸºå‡†æ—¥ç”¨æˆ·æ•°']}")
            print(f"ç•™å­˜ç”¨æˆ·æ•°: {result['ç•™å­˜ç”¨æˆ·æ•°']}")
            print(f"ç•™å­˜ç‡: {result['ç•™å­˜ç‡']}")

            if result['ç•™å­˜ç”¨æˆ·è¯¦æƒ…']:
                print("ç•™å­˜ç”¨æˆ·è¯¦æƒ…:")
                for ip, region in result['ç•™å­˜ç”¨æˆ·è¯¦æƒ…'][:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                    print(f"  - IP: {ip}, åœ°åŸŸ: {region}")
                if len(result['ç•™å­˜ç”¨æˆ·è¯¦æƒ…']) > 5:
                    print(f"  ... è¿˜æœ‰{len(result['ç•™å­˜ç”¨æˆ·è¯¦æƒ…']) - 5}ä¸ªç”¨æˆ·")

        client.close()
        return retention_results

    except Exception as e:
        print(f"ç•™å­˜åˆ†æå‡ºé”™: {e}")
        return None



def custom_retention_analysis():
    """
    ç•™å­˜åˆ†æ - äº¤äº’å¼é€‰æ‹©æ—¥æœŸèŒƒå›´
    """
    print("\n" + "="*60)
    print("ğŸ” ç•™å­˜åˆ†æ")
    print("="*60)

    try:
        # è·å–æ—¥æœŸèŒƒå›´
        print("\nğŸ“… è®¾ç½®æ—¥æœŸèŒƒå›´ (æ ¼å¼: YYYY-MM-DDï¼Œç•™ç©ºè¡¨ç¤ºä¸é™åˆ¶)")
        start_date = input("å¼€å§‹æ—¥æœŸ (å¦‚: 2025-07-17): ").strip()
        end_date = input("ç»“æŸæ—¥æœŸ (å¦‚: 2025-07-27): ").strip()

        start_date = start_date if start_date else None
        end_date = end_date if end_date else None

        # æ•´ä½“ç•™å­˜åˆ†æ
        print(f"\nğŸš€ å¼€å§‹æ•´ä½“ç•™å­˜åˆ†æ...")
        results = analyze_retention(start_date=start_date, end_date=end_date)
        return results

    except ValueError as e:
        print(f"âŒ è¾“å…¥æ ¼å¼é”™è¯¯: {e}")
        return None
    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹å‡ºé”™: {e}")
        return None

# ä¸»ç¨‹åºæ‰§è¡Œ
if __name__ == "__main__":
    print("\n" + "="*60)
    print("ğŸ¯ æ•°æ®å¤„ç†ä¸ç•™å­˜åˆ†æç³»ç»Ÿ")
    print("="*60)

    try:
        print("\nè¯·é€‰æ‹©åŠŸèƒ½:")
        print("1. æ•°æ®å¤„ç†ä¸å­˜å‚¨ (ä»Excel/CSVè¯»å–æ•°æ®å¹¶å­˜å…¥æ•°æ®åº“)")
        print("2. ç•™å­˜åˆ†æ (ä»æ•°æ®åº“è¯»å–æ•°æ®è¿›è¡Œç•™å­˜åˆ†æ)")
        print("3. å®Œæ•´æµç¨‹ (å…ˆå¤„ç†æ•°æ®ï¼Œå†è¿›è¡Œåˆ†æ)")

        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1/2/3): ").strip()

        if choice == "1":
            # æ•°æ®å¤„ç†ä¸å­˜å‚¨
            file_path = input("\nè¯·è¾“å…¥æ•°æ®æ–‡ä»¶è·¯å¾„ (å¦‚: 717.csv æˆ– data.xlsx): ").strip()
            if not file_path:
                file_path = "717.csv"  # é»˜è®¤æ–‡ä»¶

            success = process_and_store_data(file_path)
            if success:
                print("\nğŸ‰ æ•°æ®å¤„ç†ä¸å­˜å‚¨å®Œæˆï¼")
            else:
                print("\nâŒ æ•°æ®å¤„ç†å¤±è´¥ï¼")

        elif choice == "2":
            # ç•™å­˜åˆ†æ
            print("\nğŸ” å¼€å§‹ç•™å­˜åˆ†æ...")
            custom_retention_analysis()

        elif choice == "3":
            # å®Œæ•´æµç¨‹
            file_path = input("\nè¯·è¾“å…¥æ•°æ®æ–‡ä»¶è·¯å¾„ (å¦‚: 717.csv æˆ– data.xlsx): ").strip()
            if not file_path:
                file_path = "717.csv"  # é»˜è®¤æ–‡ä»¶

            print("\nğŸ“Š ç¬¬ä¸€æ­¥ï¼šæ•°æ®å¤„ç†ä¸å­˜å‚¨")
            success = process_and_store_data(file_path)

            if success:
                print("\nğŸ” ç¬¬äºŒæ­¥ï¼šç•™å­˜åˆ†æ")
                custom_retention_analysis()
            else:
                print("\nâŒ æ•°æ®å¤„ç†å¤±è´¥ï¼Œæ— æ³•è¿›è¡Œç•™å­˜åˆ†æï¼")

        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼")

    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
    except Exception as e:
        print(f"\nâŒ æ‰§è¡Œå‡ºé”™: {e}")

    print("\n" + "="*60)
    print("âœ… ç¨‹åºæ‰§è¡Œå®Œæˆï¼")
    print("="*60)
